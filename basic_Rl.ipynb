{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf70392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32f83fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom environment needs to inherit from the abstract class gym.Env\n",
    "class Walk_Motivation(gym.Env):\n",
    "    #add the metadata attribute to your class\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "    def __init__(self):\n",
    "        # define the environment's action_space and observation space\n",
    "        \n",
    "        '''Box-The argument low specifies the lower bound of each dimension and high specifies the upper bounds\n",
    "        '''\n",
    "        #  walk from 0 to 100\n",
    "        self.observation_space= gym.spaces.Box(low=0, high=100, shape=(1,))\n",
    "         \n",
    "        # action_space are move forward, move backward or stay where you are\n",
    "        self.action_space= gym.spaces.Discrete(3)\n",
    "        \n",
    "        # current state\n",
    "        self.state= random.randint(0,20)\n",
    "        \n",
    "        # rewards \n",
    "        self.reward=0\n",
    "    \n",
    "    def get_action_meanings(self, action):\n",
    "        action_list={0: \"Move Forward\", 1: \"Move backward\", 2:\"Stay at same position\"}\n",
    "        return action_list[action]\n",
    "    \n",
    "    def step(self, action):\n",
    "        '''defines the logic of your environment when the agent takes an actio\n",
    "        Accepts an action, computes the state of the environment after applying that action\n",
    "        '''\n",
    "        done=False\n",
    "        info={}\n",
    "      \n",
    "        #setting the state of the environment based on agent's action\n",
    "        # rewarding the agent for the action\n",
    "        if action == 0: # Move forward\n",
    "            self.state += 10\n",
    "            self.reward+=1\n",
    "        elif action == 1: # Move backward\n",
    "            self.state -=1\n",
    "            self.reward+=-1\n",
    "        elif action == 2: # stay at the same position\n",
    "            self.state \n",
    "            self.reward+=0\n",
    "            \n",
    "        # define the completion of the episode\n",
    "        if self.state>=101:\n",
    "            self.reward+=100\n",
    "            done= True\n",
    "        self.render(action)\n",
    "        return self.state, self.reward, done, info\n",
    "    def render(self,action):\n",
    "        # Visualize your environment\n",
    "        print(f\"\\n Distance Travelled:{self.state}\\n Reward Received:{self.reward} \")\n",
    "        print(f\" Action taken: {self.get_action_meanings(action)}\")\n",
    "        print(\"==================================================\")\n",
    "    def reset(self):\n",
    "        #reset your environment\n",
    "        self.state=random.randint(0,20)\n",
    "        self.reward=0\n",
    "        return self.state\n",
    "    def close(self):\n",
    "        # close the nevironment\n",
    "        self.state=0\n",
    "        self.reward=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce3f2d1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance Travelled:17\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:17\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:27\n",
      " Reward Received:1 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:37\n",
      " Reward Received:2 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:47\n",
      " Reward Received:3 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:47\n",
      " Reward Received:3 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:57\n",
      " Reward Received:4 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:67\n",
      " Reward Received:5 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:67\n",
      " Reward Received:5 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:66\n",
      " Reward Received:4 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:65\n",
      " Reward Received:3 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:64\n",
      " Reward Received:2 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:63\n",
      " Reward Received:1 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:62\n",
      " Reward Received:0 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:62\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:62\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:72\n",
      " Reward Received:1 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:72\n",
      " Reward Received:1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:71\n",
      " Reward Received:0 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:71\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:71\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:70\n",
      " Reward Received:-1 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:80\n",
      " Reward Received:0 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:80\n",
      " Reward Received:0 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:79\n",
      " Reward Received:-1 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:78\n",
      " Reward Received:-2 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:78\n",
      " Reward Received:-2 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:88\n",
      " Reward Received:-1 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:88\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:88\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:98\n",
      " Reward Received:0 \n",
      " Action taken: Move Forward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:97\n",
      " Reward Received:-1 \n",
      " Action taken: Move backward\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:97\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:97\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:97\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:97\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:97\n",
      " Reward Received:-1 \n",
      " Action taken: Stay at same position\n",
      "==================================================\n",
      "\n",
      " Distance Travelled:107\n",
      " Reward Received:100 \n",
      " Action taken: Move Forward\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "env= Walk_Motivation()\n",
    "done=False\n",
    "state= env.reset()\n",
    "while not done:\n",
    "    \n",
    "   \n",
    "    action= env.action_space.sample()\n",
    "   \n",
    "    state, reward, done, info = env.step(action)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0af511",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[1;32m      6\u001b[0m     observation, reward, terminated, truncated,info\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n\u001b[0;32m----> 7\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective achived\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn_rl/lib/python3.8/site-packages/gym/core.py:329\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    327\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;124;03m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn_rl/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn_rl/lib/python3.8/site-packages/gym/wrappers/env_checker.py:55\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn_rl/lib/python3.8/site-packages/gym/envs/classic_control/mountain_car.py:264\u001b[0m, in \u001b[0;36mMountainCarEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes=10000\n",
    "env=gym.make('MountainCar-v0', render_mode=\"human\")\n",
    "print(env.action_space.seed(10))\n",
    "observation, info= env.reset(seed=10)\n",
    "for i in range(episodes):\n",
    "    observation, reward, terminated, truncated,info= env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "if terminated:\n",
    "    print(\"objective achived\")\n",
    "    env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101e645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
